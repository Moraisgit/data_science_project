{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Project directory and important variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_directory = \"C:/Users/tiago/Desktop/DS/data_science_project\"\n",
    "\n",
    "file_tag: str = \"forecast_ny_arrests\"\n",
    "filename: str = f\"{path_to_directory}/datasets/{file_tag}.csv\"\n",
    "target: str = \"Manhattan\"\n",
    "timecol: str = \"Date\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Forecasting**\n",
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from math import sqrt\n",
    "from dslabs_functions import plot_multibar_chart, FORECAST_MEASURES, HEIGHT, Axes, subplots, set_chart_labels, BarContainer, ndarray, FONT_TEXT\n",
    "from numpy import arange\n",
    "\n",
    "\n",
    "def series_train_test_split(data: Series, trn_pct: float = 0.90) -> tuple[Series, Series]:\n",
    "    trn_size: int = int(len(data) * trn_pct)\n",
    "    df_cp: Series = data.copy()\n",
    "    train: Series = df_cp.iloc[:trn_size, -1]\n",
    "    test: Series = df_cp.iloc[trn_size:, -1]\n",
    "    return train, test\n",
    "\n",
    "def plot_multibar_chart(\n",
    "    group_labels: list,\n",
    "    yvalues: dict,\n",
    "    ax: Axes = None,  # type: ignore\n",
    "    title: str = \"\",\n",
    "    xlabel: str = \"\",\n",
    "    ylabel: str = \"\",\n",
    "    percentage: bool = False,\n",
    ") -> Axes | list[Axes]:\n",
    "    if ax is None:\n",
    "        ax = gca()\n",
    "    ax = set_chart_labels(ax=ax, title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    if percentage:\n",
    "        ax.set_ylim(0.0, 1.0)\n",
    "    bar_labels: list = list(yvalues.keys())\n",
    "\n",
    "    # This is the location for each bar\n",
    "    index: ndarray = arange(len(group_labels))\n",
    "    bar_width: float = 0.8 / len(bar_labels)\n",
    "    ax.set_xticks(index + bar_width / 2, labels=group_labels)\n",
    "\n",
    "    for i in range(len(bar_labels)):\n",
    "        bar_yvalues = yvalues[bar_labels[i]]\n",
    "        values: BarContainer = ax.bar(\n",
    "            index + i * bar_width,\n",
    "            bar_yvalues,\n",
    "            width=bar_width,\n",
    "            label=bar_labels[i],\n",
    "        )\n",
    "        format = \"%.2f\" if percentage else \"%.2f\"  # Updated format for better precision\n",
    "        ax.bar_label(values, fmt=format, fontproperties=FONT_TEXT)\n",
    "        if any(y < 0 for y in bar_yvalues) and percentage:\n",
    "            ax.set_ylim(-1.0, 1.0)\n",
    "    ax.legend(fontsize=\"xx-small\")\n",
    "\n",
    "    return ax\n",
    "\n",
    "def plot_forecasting_eval(trn: Series, tst: Series, prd_trn: Series, prd_tst: Series, title: str = \"\") -> list[Axes]:\n",
    "    ev1: dict = {\n",
    "        \"RMSE\": [sqrt(FORECAST_MEASURES[\"MSE\"](trn, prd_trn)), sqrt(FORECAST_MEASURES[\"MSE\"](tst, prd_tst))],\n",
    "        \"MAE\": [FORECAST_MEASURES[\"MAE\"](trn, prd_trn), FORECAST_MEASURES[\"MAE\"](tst, prd_tst)],\n",
    "    }\n",
    "    ev2: dict = {\n",
    "        \"MAPE\": [FORECAST_MEASURES[\"MAPE\"](trn, prd_trn), FORECAST_MEASURES[\"MAPE\"](tst, prd_tst)],\n",
    "        \"R2\": [FORECAST_MEASURES[\"R2\"](trn, prd_trn), FORECAST_MEASURES[\"R2\"](tst, prd_tst)],\n",
    "    }\n",
    "\n",
    "    # print(eval1, eval2)\n",
    "    fig, axs = subplots(1, 2, figsize=(1.5 * HEIGHT, 0.75 * HEIGHT), squeeze=True)\n",
    "    fig.suptitle(title)\n",
    "    plot_multibar_chart([\"train\", \"test\"], ev1, ax=axs[0], title=\"Scale-dependent error\", percentage=False)\n",
    "    plot_multibar_chart([\"train\", \"test\"], ev2, ax=axs[1], title=\"Percentage error\", percentage=True)\n",
    "\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Simple Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin\n",
    "from matplotlib.pyplot import savefig\n",
    "\n",
    "\n",
    "class SimpleAvgRegressor(RegressorMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mean: float = 0.0\n",
    "        return\n",
    "\n",
    "    def fit(self, X: Series):\n",
    "        self.mean = X.mean()\n",
    "        return\n",
    "\n",
    "    def predict(self, X: Series) -> Series:\n",
    "        prd: list = len(X) * [self.mean]\n",
    "        prd_series: Series = Series(prd)\n",
    "        prd_series.index = X.index\n",
    "        return prd_series\n",
    "    \n",
    "\n",
    "from pandas import read_csv, DataFrame, Series\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\";\", decimal=\".\", parse_dates=True, infer_datetime_format=True)\n",
    "series: Series = data[target]\n",
    "\n",
    "train, test = series_train_test_split(data, trn_pct=0.90)\n",
    "\n",
    "fr_mod = SimpleAvgRegressor()\n",
    "fr_mod.fit(train)\n",
    "prd_trn: Series = fr_mod.predict(train)\n",
    "prd_tst: Series = fr_mod.predict(test)\n",
    "\n",
    "plot_forecasting_eval(train, test, prd_trn, prd_tst, title=f\"{file_tag} - Simple Average\")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting results obtained with Simple Average model.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dslabs_functions import PAST_COLOR, FUTURE_COLOR, PRED_FUTURE_COLOR\n",
    "\n",
    "def plot_forecasting_series(\n",
    "    trn: Series,\n",
    "    tst: Series,\n",
    "    prd_tst: Series,\n",
    "    title: str = \"\",\n",
    "    xlabel: str = \"time\",\n",
    "    ylabel: str = \"\",\n",
    ") -> list[Axes]:\n",
    "    fig, ax = subplots(1, 1, squeeze=True)\n",
    "    fig.suptitle(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.plot(trn.index, trn.values, label=\"train\", color=PAST_COLOR)\n",
    "    ax.plot(tst.index, tst.values, label=\"test\", color=FUTURE_COLOR)\n",
    "    ax.plot(prd_tst.index, prd_tst.values, \"--\", label=\"test prediction\", color=PRED_FUTURE_COLOR)\n",
    "    ax.legend(prop={\"size\": 5})\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "plot_forecasting_series(\n",
    "    train,\n",
    "    test,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - Simple Average\",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting plots obtained with Simple Average model.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Persistence Model**\n",
    "### Long Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "\n",
    "class PersistenceOptimistRegressor(RegressorMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.last: float = 0.0\n",
    "        return\n",
    "\n",
    "    def fit(self, X: Series):\n",
    "        self.last = X.iloc[-1]\n",
    "        # print(self.last)\n",
    "        return\n",
    "\n",
    "    def predict(self, X: Series):\n",
    "        prd: list = X.shift().values.ravel()\n",
    "        prd[0] = self.last\n",
    "        prd_series: Series = Series(prd)\n",
    "        prd_series.index = X.index\n",
    "        return prd_series\n",
    "    \n",
    "from pandas import read_csv, DataFrame, Series\n",
    "from matplotlib.pyplot import savefig\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\";\", decimal=\".\", parse_dates=True, infer_datetime_format=True)\n",
    "series: Series = data[target]\n",
    "\n",
    "train, test = series_train_test_split(data, trn_pct=0.90)\n",
    "\n",
    "fr_mod = PersistenceOptimistRegressor()\n",
    "fr_mod.fit(train)\n",
    "prd_trn: Series = fr_mod.predict(train)\n",
    "prd_tst: Series = fr_mod.predict(test)\n",
    "\n",
    "plot_forecasting_eval(train, test, prd_trn, prd_tst, title=f\"{file_tag} - Persistence Optimist\")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting results obtained with Persistence model (long term).png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasting_series(\n",
    "    train,\n",
    "    test,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - Persistence Optimist\",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting plots obtained with Persistence model (long term).png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-set-behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersistenceRealistRegressor(RegressorMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.last = 0\n",
    "        self.estimations = [0]\n",
    "        self.obs_len = 0\n",
    "\n",
    "    def fit(self, X: Series):\n",
    "        for i in range(1, len(X)):\n",
    "            self.estimations.append(X.iloc[i - 1])\n",
    "        self.obs_len = len(self.estimations)\n",
    "        self.last = X.iloc[len(X) - 1]\n",
    "        prd_series: Series = Series(self.estimations)\n",
    "        prd_series.index = X.index\n",
    "        return prd_series\n",
    "\n",
    "    def predict(self, X: Series):\n",
    "        prd: list = len(X) * [self.last]\n",
    "        prd_series: Series = Series(prd)\n",
    "        prd_series.index = X.index\n",
    "        return prd_series\n",
    "    \n",
    "fr_mod = PersistenceRealistRegressor()\n",
    "fr_mod.fit(train)\n",
    "prd_trn: Series = fr_mod.predict(train)\n",
    "prd_tst: Series = fr_mod.predict(test)\n",
    "\n",
    "plot_forecasting_eval(train, test, prd_trn, prd_tst, title=f\"{file_tag} - Persistence Realist\")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting results obtained with Persistence model (one-set-behind).png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasting_series(\n",
    "    train,\n",
    "    test,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - Persistence Realist\",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting plots obtained with Persistence model (one-set-behind).png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exponential Smoothing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, Series\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from dslabs_functions import FORECAST_MEASURES, DELTA_IMPROVE, set_chart_xticks, LINE_COLOR, FILL_COLOR, std, gca\n",
    "\n",
    "def plot_line_chart(\n",
    "    xvalues: list,\n",
    "    yvalues: list,\n",
    "    ax: Axes = None,  # type: ignore\n",
    "    title: str = \"\",\n",
    "    xlabel: str = \"\",\n",
    "    ylabel: str = \"\",\n",
    "    name: str = \"\",\n",
    "    percentage: bool = False,\n",
    "    show_stdev: bool = False,\n",
    ") -> Axes:\n",
    "    if ax is None:\n",
    "        ax = gca()\n",
    "    ax = set_chart_labels(ax=ax, title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    ax = set_chart_xticks(xvalues, ax, percentage=percentage)\n",
    "    if any(y < 0 for y in yvalues) and percentage:\n",
    "            ax.set_ylim(-30.0, 1.0)\n",
    "    ax.plot(xvalues, yvalues, c=LINE_COLOR, label=name)\n",
    "    if show_stdev:\n",
    "        stdev: float = round(std(yvalues), 3)\n",
    "        y_bottom: list[float] = [(y - stdev) for y in yvalues]\n",
    "        y_top: list[float] = [(y + stdev) for y in yvalues]\n",
    "        ax.fill_between(xvalues, y_bottom, y_top, color=FILL_COLOR, alpha=0.2)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def exponential_smoothing_study(train: Series, test: Series, measure: str = \"R2\"):\n",
    "    alpha_values = [i / 10 for i in range(1, 10)]\n",
    "    flag = measure == \"R2\" or measure == \"MAPE\"\n",
    "    best_model = None\n",
    "    best_params: dict = {\"name\": \"Exponential Smoothing\", \"metric\": measure, \"params\": ()}\n",
    "    best_performance: float = -100000\n",
    "\n",
    "    yvalues = []\n",
    "    for alpha in alpha_values:\n",
    "        tool = SimpleExpSmoothing(train)\n",
    "        model = tool.fit(smoothing_level=alpha, optimized=False)\n",
    "        prd_tst = model.forecast(steps=len(test))\n",
    "\n",
    "        eval: float = FORECAST_MEASURES[measure](test, prd_tst)\n",
    "        # print(w, eval)\n",
    "        if eval > best_performance and abs(eval - best_performance) > DELTA_IMPROVE:\n",
    "            best_performance: float = eval\n",
    "            best_params[\"params\"] = (alpha,)\n",
    "            best_model = model\n",
    "        yvalues.append(eval)\n",
    "\n",
    "    print(f\"Exponential Smoothing best with alpha={best_params['params'][0]:.0f} -> {measure}={best_performance}\")\n",
    "    plot_line_chart(\n",
    "        alpha_values,\n",
    "        yvalues,\n",
    "        title=f\"Exponential Smoothing ({measure})\",\n",
    "        xlabel=\"alpha\",\n",
    "        ylabel=measure,\n",
    "        percentage=flag,\n",
    "    )\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "measure: str = \"R2\"\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\";\", decimal=\".\", parse_dates=True, infer_datetime_format=True)\n",
    "series: Series = data[target]\n",
    "train, test = series_train_test_split(data, trn_pct=0.90)\n",
    "\n",
    "best_model, best_params = exponential_smoothing_study(train, test, measure=measure)\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting study over different parameterisations of the Exponential Smoothing algorithm.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_params[\"params\"]\n",
    "prd_trn = best_model.predict(start=0, end=len(train) - 1)\n",
    "prd_tst = best_model.forecast(steps=len(test))\n",
    "\n",
    "plot_forecasting_eval(train, test, prd_trn, prd_tst, title=f\"{file_tag} - Exponential Smoothing alpha={params[0]}\")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting results obtained with the best parameterisation of Exponential Smoothing algorithm.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasting_series(\n",
    "    train,\n",
    "    test,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - Exponential Smoothing \",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting plots obtained with the best parameterisation of Exponential Smoothing algorithm.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Rolling Mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from pandas import Series\n",
    "from sklearn.base import RegressorMixin\n",
    "from dslabs_functions import FORECAST_MEASURES, DELTA_IMPROVE, plot_line_chart\n",
    "from pandas import read_csv, DataFrame\n",
    "from matplotlib.pyplot import figure, savefig\n",
    "\n",
    "def plot_line_chart(\n",
    "    xvalues: list,\n",
    "    yvalues: list,\n",
    "    ax: Axes = None,  # type: ignore\n",
    "    title: str = \"\",\n",
    "    xlabel: str = \"\",\n",
    "    ylabel: str = \"\",\n",
    "    name: str = \"\",\n",
    "    percentage: bool = False,\n",
    "    show_stdev: bool = False,\n",
    ") -> Axes:\n",
    "    if ax is None:\n",
    "        ax = gca()\n",
    "    ax = set_chart_labels(ax=ax, title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    ax = set_chart_xticks(xvalues, ax, percentage=percentage)\n",
    "    if any(y < 0 for y in yvalues) and percentage:\n",
    "            ax.set_ylim(-100.0, 1.0)\n",
    "    ax.plot(xvalues, yvalues, c=LINE_COLOR, label=name)\n",
    "    if show_stdev:\n",
    "        stdev: float = round(std(yvalues), 3)\n",
    "        y_bottom: list[float] = [(y - stdev) for y in yvalues]\n",
    "        y_top: list[float] = [(y + stdev) for y in yvalues]\n",
    "        ax.fill_between(xvalues, y_bottom, y_top, color=FILL_COLOR, alpha=0.2)\n",
    "    return ax\n",
    "\n",
    "class RollingMeanRegressor(RegressorMixin):\n",
    "    def __init__(self, win: int = 3):\n",
    "        super().__init__()\n",
    "        self.win_size = win\n",
    "        self.memory: list = []\n",
    "\n",
    "    def fit(self, X: Series):\n",
    "        self.memory = X.iloc[-self.win_size :]\n",
    "        # print(self.memory)\n",
    "        return\n",
    "\n",
    "    def predict(self, X: Series):\n",
    "        estimations = self.memory.tolist()\n",
    "        predictions = []\n",
    "        for _ in range(len(X)):\n",
    "            new_value = mean(estimations[-self.win_size:])  # Use only the last `win_size` values\n",
    "            estimations.append(new_value)  # Update the memory with the new value\n",
    "            predictions.append(new_value)  # Store the prediction\n",
    "        prd_series: Series = Series(predictions, index=X.index)  # Ensure the index matches the input\n",
    "        return prd_series\n",
    "\n",
    "    \n",
    "\n",
    "def rolling_mean_study(train: Series, test: Series, measure: str = \"R2\"):\n",
    "    win_size = (1, 5, 10, 20, 40, 50, 80, 160)\n",
    "    flag = measure == \"R2\" or measure == \"MAPE\"\n",
    "    best_model = None\n",
    "    best_params: dict = {\"name\": \"Rolling Mean\", \"metric\": measure, \"params\": ()}\n",
    "    best_performance: float = -100000\n",
    "\n",
    "    yvalues = []\n",
    "    for w in win_size:\n",
    "        pred = RollingMeanRegressor(win=w)\n",
    "        pred.fit(train)\n",
    "        prd_tst = pred.predict(test)\n",
    "\n",
    "        eval: float = FORECAST_MEASURES[measure](test, prd_tst)\n",
    "        # print(w, eval)\n",
    "        if eval > best_performance and abs(eval - best_performance) > DELTA_IMPROVE:\n",
    "            best_performance: float = eval\n",
    "            best_params[\"params\"] = (w,)\n",
    "            best_model = pred\n",
    "        yvalues.append(eval)\n",
    "\n",
    "    print(f\"Rolling Mean best with win={best_params['params'][0]:.0f} -> {measure}={best_performance}\")\n",
    "    print(yvalues)\n",
    "    plot_line_chart(\n",
    "        win_size, yvalues, title=f\"Rolling Mean ({measure})\", xlabel=\"window size\", ylabel=measure, percentage=flag\n",
    "    )\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\";\", decimal=\".\", parse_dates=True, infer_datetime_format=True)\n",
    "series: Series = data[target]\n",
    "\n",
    "train, test = series_train_test_split(data, trn_pct=0.90)\n",
    "\n",
    "fig = figure()\n",
    "best_model, best_params = rolling_mean_study(train, test)\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting study over different parameterisations of the Rolling Mean algorithm.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_params[\"params\"]\n",
    "prd_trn: Series = best_model.predict(train)\n",
    "prd_tst: Series = best_model.predict(test)\n",
    "\n",
    "plot_forecasting_eval(train, test, prd_trn, prd_tst, title=f\"{file_tag} - Rolling Mean (win={params[0]})\")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting results obtained with the best parameterisation of Rolling Mean algorithm.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasting_series(\n",
    "    train,\n",
    "    test,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - Rolling Mean (win={params[0]})\",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting plots obtained with the best parameterisation of Rolling Mean algorithm.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "from pandas import read_csv, DataFrame, Series\n",
    "from matplotlib.pyplot import savefig\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\";\", decimal=\".\", parse_dates=True, infer_datetime_format=True)\n",
    "series: Series = data[target]\n",
    "train, test = series_train_test_split(data, trn_pct=0.90)\n",
    "\n",
    "trnX = arange(len(train)).reshape(-1, 1)\n",
    "trnY = train.to_numpy()\n",
    "tstX = arange(len(train), len(data)).reshape(-1, 1)\n",
    "tstY = test.to_numpy()\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(trnX, trnY)\n",
    "\n",
    "prd_trn: Series = Series(model.predict(trnX), index=train.index)\n",
    "prd_tst: Series = Series(model.predict(tstX), index=test.index)\n",
    "\n",
    "plot_forecasting_eval(train, test, prd_trn, prd_tst, title=f\"{file_tag} - Linear Regression\")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting results obtained with Linear Regression model.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasting_series(\n",
    "    train,\n",
    "    test,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - Linear Regression\",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting plots obtained with Linear Regression model.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ARIMA**\n",
    "### Only with target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, Series\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\";\", decimal=\".\", parse_dates=True, infer_datetime_format=True)\n",
    "series: Series = data[target]\n",
    "train, test = series_train_test_split(data, trn_pct=0.90)\n",
    "\n",
    "predictor = ARIMA(train, order=(3, 1, 2))\n",
    "model = predictor.fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, savefig, subplots\n",
    "from dslabs_functions import FORECAST_MEASURES, DELTA_IMPROVE\n",
    "\n",
    "def plot_multiline_chart(\n",
    "    xvalues: list,\n",
    "    yvalues: dict,\n",
    "    ax: Axes = None,  # type: ignore\n",
    "    title: str = \"\",\n",
    "    xlabel: str = \"\",\n",
    "    ylabel: str = \"\",\n",
    "    percentage: bool = False,\n",
    ") -> Axes:\n",
    "    if ax is None:\n",
    "        ax = gca()\n",
    "    ax = set_chart_labels(ax=ax, title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    ax = set_chart_xticks(xvalues, ax=ax, percentage=percentage)\n",
    "    legend: list = []\n",
    "    for name, y in yvalues.items():\n",
    "        ax.plot(xvalues, y)\n",
    "        legend.append(name)\n",
    "        if any(v < 0 for v in y) and percentage:\n",
    "            ax.set_ylim(-15.0, 1.0)\n",
    "    ax.legend(legend, fontsize=\"xx-small\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "def arima_study(train: Series, test: Series, measure: str = \"R2\"):\n",
    "    d_values = (0, 1, 2)\n",
    "    p_params = (1, 2, 3, 5, 7, 10)\n",
    "    q_params = (1, 3, 5, 7)\n",
    "\n",
    "    flag = measure == \"R2\" or measure == \"MAPE\"\n",
    "    best_model = None\n",
    "    best_params: dict = {\"name\": \"ARIMA\", \"metric\": measure, \"params\": ()}\n",
    "    best_performance: float = -100000\n",
    "\n",
    "    fig, axs = subplots(1, len(d_values), figsize=(len(d_values) * HEIGHT, HEIGHT))\n",
    "    for i in range(len(d_values)):\n",
    "        d: int = d_values[i]\n",
    "        values = {}\n",
    "        for q in q_params:\n",
    "            yvalues = []\n",
    "            for p in p_params:\n",
    "                arima = ARIMA(train, order=(p, d, q))\n",
    "                model = arima.fit()\n",
    "                prd_tst = model.forecast(steps=len(test), signal_only=False)\n",
    "                eval: float = FORECAST_MEASURES[measure](test, prd_tst)\n",
    "                # print(f\"ARIMA ({p}, {d}, {q})\", eval)\n",
    "                if eval > best_performance and abs(eval - best_performance) > DELTA_IMPROVE:\n",
    "                    best_performance: float = eval\n",
    "                    best_params[\"params\"] = (p, d, q)\n",
    "                    best_model = model\n",
    "                yvalues.append(eval)\n",
    "            values[q] = yvalues\n",
    "        print(values)\n",
    "        plot_multiline_chart(\n",
    "            p_params, values, ax=axs[i], title=f\"ARIMA d={d} ({measure})\", xlabel=\"p\", ylabel=measure, percentage=flag\n",
    "        )\n",
    "    print(\n",
    "        f\"ARIMA best results achieved with (p,d,q)=({best_params['params'][0]:.0f}, {best_params['params'][1]:.0f}, {best_params['params'][2]:.0f}) ==> measure={best_performance:.2f}\"\n",
    "    )\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "\n",
    "best_model, best_params = arima_study(train, test, measure=measure)\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting study over different parameterisations of the ARIMA algorithm, only with the target variable.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_params[\"params\"]\n",
    "prd_trn = best_model.predict(start=0, end=len(train) - 1)\n",
    "prd_tst = best_model.forecast(steps=len(test))\n",
    "\n",
    "plot_forecasting_eval(\n",
    "    train, test, prd_trn, prd_tst, title=f\"{file_tag} - ARIMA (p={params[0]}, d={params[1]}, q={params[2]})\"\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting results obtained with the best parameterisation of ARIMA algorithm, only with the target variable.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasting_series(\n",
    "    train,\n",
    "    test,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - ARIMA \",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting plots obtained with the best parameterisation of ARIMA algorithm, only with the target variable.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, Series\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def series_train_test_split_exog(data: DataFrame, trn_pct: float = 0.90) -> tuple[Series, Series, DataFrame, DataFrame]:\n",
    "    trn_size: int = int(len(data) * trn_pct)\n",
    "    target: Series = data.iloc[:, -1]  # Assuming the target is the last column\n",
    "    exog: DataFrame = data.iloc[:, :-1]  # All columns except the last one\n",
    "    \n",
    "    train_target: Series = target.iloc[:trn_size]\n",
    "    test_target: Series = target.iloc[trn_size:]\n",
    "    train_exog: DataFrame = exog.iloc[:trn_size]\n",
    "    test_exog: DataFrame = exog.iloc[trn_size:]\n",
    "    \n",
    "    return train_target, test_target, train_exog, test_exog\n",
    "\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\";\", decimal=\".\", parse_dates=True, infer_datetime_format=True)\n",
    "series: Series = data[target]\n",
    "train_target, test_target, train_exog, test_exog = series_train_test_split_exog(data, trn_pct=0.90)\n",
    "\n",
    "predictor = ARIMA(train_target, exog=train_exog, order=(3, 1, 2))\n",
    "model = predictor.fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiline_chart(\n",
    "    xvalues: list,\n",
    "    yvalues: dict,\n",
    "    ax: Axes = None,  # type: ignore\n",
    "    title: str = \"\",\n",
    "    xlabel: str = \"\",\n",
    "    ylabel: str = \"\",\n",
    "    percentage: bool = False,\n",
    ") -> Axes:\n",
    "    if ax is None:\n",
    "        ax = gca()\n",
    "    ax = set_chart_labels(ax=ax, title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    ax = set_chart_xticks(xvalues, ax=ax, percentage=percentage)\n",
    "    legend: list = []\n",
    "    for name, y in yvalues.items():\n",
    "        ax.plot(xvalues, y)\n",
    "        legend.append(name)\n",
    "        if any(v < 0 for v in y) and percentage:\n",
    "            ax.set_ylim(-16.0, 1.0)\n",
    "    ax.legend(legend, fontsize=\"xx-small\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "def arima_study(train: Series, test: Series, train_exog: Series, test_exog: Series, measure: str = \"R2\"):\n",
    "    d_values = (0, 1, 2)\n",
    "    p_params = (1, 2, 3, 5, 7, 10)\n",
    "    q_params = (1, 3, 5, 7)\n",
    "\n",
    "    flag = measure == \"R2\" or measure == \"MAPE\"\n",
    "    best_model = None\n",
    "    best_params: dict = {\"name\": \"ARIMA\", \"metric\": measure, \"params\": ()}\n",
    "    best_performance: float = -100000\n",
    "\n",
    "    fig, axs = subplots(1, len(d_values), figsize=(len(d_values) * HEIGHT, HEIGHT))\n",
    "    for i in range(len(d_values)):\n",
    "        d: int = d_values[i]\n",
    "        values = {}\n",
    "        for q in q_params:\n",
    "            yvalues = []\n",
    "            for p in p_params:\n",
    "                arima = ARIMA(train, exog=train_exog, order=(p, d, q))\n",
    "                model = arima.fit()\n",
    "                prd_tst = model.forecast(steps=len(test), signal_only=False, exog=test_exog)\n",
    "                eval: float = FORECAST_MEASURES[measure](test, prd_tst)\n",
    "                if eval > best_performance and abs(eval - best_performance) > DELTA_IMPROVE:\n",
    "                    best_performance: float = eval\n",
    "                    best_params[\"params\"] = (p, d, q)\n",
    "                    best_model = model\n",
    "                yvalues.append(eval)\n",
    "            values[q] = yvalues\n",
    "        print(values)\n",
    "        plot_multiline_chart(\n",
    "            p_params, values, ax=axs[i], title=f\"ARIMA d={d} ({measure})\", xlabel=\"p\", ylabel=measure, percentage=flag\n",
    "        )\n",
    "    print(\n",
    "        f\"ARIMA best results achieved with (p,d,q)=({best_params['params'][0]:.0f}, {best_params['params'][1]:.0f}, {best_params['params'][2]:.0f}) ==> measure={best_performance:.2f}\"\n",
    "    )\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "\n",
    "best_model, best_params = arima_study(train_target, test_target, train_exog=train_exog, test_exog=test_exog, measure=measure)\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting study over different parameterisations of the ARIMA algorithm with multiple variables.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_params[\"params\"]\n",
    "prd_trn = best_model.predict(start=0, end=len(train_target) - 1, exog=train_exog)\n",
    "prd_tst = best_model.forecast(steps=len(test_target), exog=test_exog)\n",
    "\n",
    "plot_forecasting_eval(\n",
    "    train_target, test_target, prd_trn, prd_tst, title=f\"{file_tag} - ARIMA (p={params[0]}, d={params[1]}, q={params[2]})\"\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting results obtained with the best parameterisation of ARIMA algorithm with multiple variables.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecasting_series(\n",
    "    train,\n",
    "    test,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - ARIMA \",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting plots obtained with the best parameterisation of ARIMA algorithm with multiple variables.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LSTMs**\n",
    "### Only with target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad, tensor\n",
    "from torch.nn import LSTM, Linear, Module, MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "def prepare_dataset_for_lstm(series, seq_length: int = 4):\n",
    "    setX: list = []\n",
    "    setY: list = []\n",
    "    for i in range(len(series) - seq_length):\n",
    "        past = series[i : i + seq_length]\n",
    "        future = series[i + 1 : i + seq_length + 1]\n",
    "        setX.append(past)\n",
    "        setY.append(future)\n",
    "    return tensor(setX), tensor(setY)\n",
    "\n",
    "\n",
    "class DS_LSTM(Module):\n",
    "    def __init__(self, train, input_size: int = 1, hidden_size: int = 50, num_layers: int = 1, length: int = 4):\n",
    "        super().__init__()\n",
    "        self.lstm = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = Linear(hidden_size, 1)\n",
    "        self.optimizer = Adam(self.parameters())\n",
    "        self.loss_fn = MSELoss()\n",
    "\n",
    "        trnX, trnY = prepare_dataset_for_lstm(train, seq_length=length)\n",
    "        self.loader = DataLoader(TensorDataset(trnX, trnY), shuffle=True, batch_size=len(train) // 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self):\n",
    "        self.train()\n",
    "        for batchX, batchY in self.loader:\n",
    "            y_pred = self(batchX)\n",
    "            loss = self.loss_fn(y_pred, batchY)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        with no_grad():\n",
    "            y_pred = self(X)\n",
    "        return y_pred[:, -1, :]\n",
    "    \n",
    "from pandas import read_csv, DataFrame, Series\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\";\", decimal=\".\", parse_dates=True, infer_datetime_format=True)\n",
    "series = data[[target]].values.astype(\"float32\")\n",
    "\n",
    "train_size = int(len(series) * 0.90)\n",
    "train, test = series[:train_size], series[train_size:]\n",
    "\n",
    "model = DS_LSTM(train, input_size=1, hidden_size=50, num_layers=1)\n",
    "loss = model.fit()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torch\n",
    "from matplotlib.pyplot import subplots, savefig\n",
    "from dslabs_functions import FORECAST_MEASURES, DELTA_IMPROVE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def lstm_study(train, test, nr_episodes: int = 1000, measure: str = \"R2\", device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    sequence_size = [2, 4, 8] \n",
    "    nr_hidden_units = [25, 50, 100] \n",
    "\n",
    "    step: int = nr_episodes // 10\n",
    "    episodes = list(range(0, nr_episodes + 1, step))\n",
    "    best_model = None\n",
    "    best_params: dict = {\"name\": \"LSTM\", \"metric\": measure, \"params\": ()}\n",
    "    best_performance: float = -100000 \n",
    "\n",
    "    _, axs = subplots(1, len(sequence_size), figsize=(len(sequence_size) * 6, 4))\n",
    "\n",
    "    for i, length in enumerate(sequence_size):\n",
    "        tstX, tstY = prepare_dataset_for_lstm(test, seq_length=length)\n",
    "        tstX, tstY = tstX.to(device), tstY.to(device)  # Move os dados para o dispositivo\n",
    "\n",
    "        ax = axs[i]\n",
    "        ax.set_title(f\"LSTM seq length={length} ({measure})\")\n",
    "        ax.set_xlabel(\"nr episodes\")\n",
    "        ax.set_ylabel(measure)\n",
    "        for hidden in nr_hidden_units:\n",
    "            yvalues = []  \n",
    "            model = DS_LSTM(train, hidden_size=hidden, length=length).to(device) \n",
    "\n",
    "            for n in range(0, nr_episodes + 1):\n",
    "                model.fit()\n",
    "                if n % step == 0: \n",
    "                    prd_tst = model.predict(tstX)\n",
    "                    eval = FORECAST_MEASURES[measure](test[length:].astype(\"float32\"), prd_tst.cpu().numpy())\n",
    "                    print(f\"seq length={length}, hidden_units={hidden}, nr_episodes={n}, eval={eval:.4f}\")\n",
    "\n",
    "                    if eval > best_performance and abs(eval - best_performance) > DELTA_IMPROVE:\n",
    "                        best_performance = eval\n",
    "                        best_params[\"params\"] = (length, hidden, n)\n",
    "                        best_model = deepcopy(model)\n",
    "\n",
    "                    yvalues.append(eval)\n",
    "\n",
    "            ax.plot(episodes, yvalues, label=f\"Hidden={hidden}\")\n",
    "\n",
    "        ax.legend()\n",
    "\n",
    "    savefig(f\"{path_to_directory}/images//Set 1 - Forecasting study over different parameterisations of LSTMs, only with the target variable.png\", bbox_inches=\"tight\")\n",
    "\n",
    "    print(\n",
    "        f\"LSTM best results achieved with length={best_params['params'][0]} \"\n",
    "        f\"hidden_units={best_params['params'][1]} and nr_episodes={best_params['params'][2]}) \"\n",
    "        f\"==> measure={best_performance:.2f}\"\n",
    "    )\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "measure = \"R2\"\n",
    "best_model, best_params = lstm_study(train, test, nr_episodes=3000, measure=measure, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_params[\"params\"]\n",
    "best_length = params[0]\n",
    "\n",
    "# Preparação dos dados\n",
    "trnX, trnY = prepare_dataset_for_lstm(train, seq_length=best_length)\n",
    "tstX, tstY = prepare_dataset_for_lstm(test, seq_length=best_length)\n",
    "\n",
    "# Previsões do modelo\n",
    "prd_trn = best_model.predict(trnX).cpu().numpy()  # Move previsões para CPU\n",
    "prd_tst = best_model.predict(tstX).cpu().numpy()  # Move previsões para CPU\n",
    "\n",
    "train_cpu = train[best_length:].astype(\"float32\")\n",
    "test_cpu = test[best_length:].astype(\"float32\")    \n",
    "\n",
    "plot_forecasting_eval(\n",
    "    train_cpu,\n",
    "    test_cpu,\n",
    "    prd_trn,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - LSTM (length={best_length}, hidden={params[1]}, epochs={params[2]})\",\n",
    ")\n",
    "\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting results obtained with the best parameterisation of LSTMs, only with the target variable.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = data[[target]]\n",
    "train, test = series[:train_size], series[train_size:]\n",
    "\n",
    "pred_series: Series = Series(prd_tst.ravel(), index=test.index[best_length:])\n",
    "\n",
    "plot_forecasting_series(\n",
    "    train[best_length:],\n",
    "    test[best_length:],\n",
    "    pred_series,\n",
    "    title=f\"{file_tag} - LSTMs \",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting plots obtained with the best parameterisation of LSTMs, only with the target variable.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad, tensor\n",
    "from torch.nn import LSTM, Linear, Module, MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "def prepare_dataset_for_lstm(data, seq_length: int = 4):\n",
    "    setX: list = []\n",
    "    setY: list = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        past = data[i : i + seq_length, :]  # All features\n",
    "        future = data[i + 1 : i + seq_length + 1, 0]  # Only the target variable\n",
    "        setX.append(past)\n",
    "        setY.append(future)\n",
    "    return tensor(setX), tensor(setY)\n",
    "\n",
    "\n",
    "\n",
    "class DS_LSTM(Module):\n",
    "    def __init__(self, train, input_size: int, hidden_size: int = 50, num_layers: int = 1, length: int = 4):\n",
    "        super().__init__()\n",
    "        self.lstm = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = Linear(hidden_size, 1)  # Output size is 1 (target variable)\n",
    "        self.optimizer = Adam(self.parameters())\n",
    "        self.loss_fn = MSELoss()\n",
    "\n",
    "        trnX, trnY = prepare_dataset_for_lstm(train, seq_length=length)\n",
    "        self.loader = DataLoader(TensorDataset(trnX, trnY), shuffle=True, batch_size=len(train) // 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)  # x: (batch, seq_length, hidden_size)\n",
    "        x = self.linear(x)  # x: (batch, seq_length, 1)\n",
    "        return x\n",
    "\n",
    "    def fit(self):\n",
    "        self.train()\n",
    "        for batchX, batchY in self.loader:\n",
    "            y_pred = self(batchX)\n",
    "            loss = self.loss_fn(y_pred[:, -1, :], batchY[:, -1])  # Compare only the last step\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def predict(self, X):\n",
    "        with no_grad():\n",
    "            y_pred = self(X)\n",
    "        return y_pred[:, -1, :]  # Return prediction for the last step\n",
    "\n",
    "\n",
    "\n",
    "data: DataFrame = read_csv(filename, index_col=timecol, sep=\";\", decimal=\".\", parse_dates=True, infer_datetime_format=True)\n",
    "series = data.values.astype(\"float32\")  # Use all features\n",
    "\n",
    "train_size = int(len(series) * 0.90)\n",
    "train, test = series[:train_size], series[train_size:]\n",
    "\n",
    "input_size = train.shape[1]  # Number of features\n",
    "model = DS_LSTM(train, input_size=input_size, hidden_size=50, num_layers=1)\n",
    "loss = model.fit()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import subplots, savefig\n",
    "\n",
    "def plot_multiline_chart(\n",
    "    xvalues: list,\n",
    "    yvalues: dict,\n",
    "    ax=None,\n",
    "    title: str = \"\",\n",
    "    xlabel: str = \"\",\n",
    "    ylabel: str = \"\",\n",
    "    percentage: bool = False,\n",
    "):\n",
    "    if ax is None:\n",
    "        ax = gca()\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    for name, y in yvalues.items():\n",
    "        ax.plot(xvalues, y, label=name)\n",
    "    ax.legend(fontsize=\"small\")\n",
    "    if percentage:\n",
    "        ax.set_ylim(0, 1)\n",
    "    return ax\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def lstm_study(train, test, nr_episodes: int = 1000, measure: str = \"R2\", device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    sequence_size = [2, 4, 8] \n",
    "    nr_hidden_units = [25, 50, 100]  \n",
    "    step: int = nr_episodes // 10  \n",
    "    episodes = list(range(0, nr_episodes + 1, step)) \n",
    "\n",
    "    best_model = None\n",
    "    best_params: dict = {\"name\": \"LSTM\", \"metric\": measure, \"params\": ()}\n",
    "    best_performance: float = -100000 \n",
    "\n",
    "    _, axs = subplots(1, len(sequence_size), figsize=(len(sequence_size) * 6, 4))\n",
    "\n",
    "    for i, length in enumerate(sequence_size):\n",
    "        tstX, tstY = prepare_dataset_for_lstm(test, seq_length=length)\n",
    "        input_size = train.shape[1]  \n",
    "\n",
    "        ax = axs[i]\n",
    "        ax.set_title(f\"LSTM seq length={length} ({measure})\")\n",
    "        ax.set_xlabel(\"Nr episodes\")\n",
    "        ax.set_ylabel(measure)\n",
    "\n",
    "        values = {}\n",
    "        for hidden in nr_hidden_units:\n",
    "            yvalues = [] \n",
    "            model = DS_LSTM(train, input_size=input_size, hidden_size=hidden, length=length)\n",
    "\n",
    "            for n in range(0, nr_episodes + 1):\n",
    "                model.fit()\n",
    "                if n % step == 0:  \n",
    "                    prd_tst = model.predict(tstX)\n",
    "                    eval: float = FORECAST_MEASURES[measure](test[length:, 0], prd_tst.numpy().flatten())\n",
    "                    print(f\"seq length={length}, hidden_units={hidden}, nr_episodes={n}, eval={eval:.4f}\")\n",
    "\n",
    "                    if eval > best_performance and abs(eval - best_performance) > DELTA_IMPROVE:\n",
    "                        best_performance = eval\n",
    "                        best_params[\"params\"] = (length, hidden, n)\n",
    "                        best_model = deepcopy(model)\n",
    "\n",
    "                    yvalues.append(eval)\n",
    "\n",
    "            values[f\"Hidden={hidden}\"] = yvalues\n",
    "\n",
    "        plot_multiline_chart(\n",
    "            episodes,\n",
    "            values,\n",
    "            ax=ax,\n",
    "            title=f\"LSTM seq length={length} ({measure})\",\n",
    "            xlabel=\"Nr episodes\",\n",
    "            ylabel=measure,\n",
    "        )\n",
    "\n",
    "    savefig(f\"{path_to_directory}/images/Set 1 - Forecasting study over different parameterisations of LSTMs with multiple variables.png\", bbox_inches=\"tight\")\n",
    "\n",
    "    print(\n",
    "        f\"LSTM best results achieved with length={best_params['params'][0]} \"\n",
    "        f\"hidden_units={best_params['params'][1]} and nr_episodes={best_params['params'][2]}) \"\n",
    "        f\"==> measure={best_performance:.2f}\"\n",
    "    )\n",
    "    return best_model, best_params\n",
    "\n",
    "best_model, best_params = lstm_study(train, test, nr_episodes=3000, measure=\"R2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import subplots, savefig\n",
    "from math import sqrt\n",
    "\n",
    "def plot_forecasting_eval(\n",
    "    trn: ndarray, tst: ndarray, prd_trn: ndarray, prd_tst: ndarray, title: str = \"\"\n",
    ") -> list[Axes]:\n",
    "\n",
    "    ev1: dict = {\n",
    "        \"RMSE\": [\n",
    "            sqrt(FORECAST_MEASURES[\"MSE\"](trn, prd_trn)),\n",
    "            sqrt(FORECAST_MEASURES[\"MSE\"](tst, prd_tst)),\n",
    "        ],\n",
    "        \"MAE\": [\n",
    "            FORECAST_MEASURES[\"MAE\"](trn, prd_trn),\n",
    "            FORECAST_MEASURES[\"MAE\"](tst, prd_tst),\n",
    "        ],\n",
    "    }\n",
    "    ev2: dict = {\n",
    "        \"MAPE\": [\n",
    "            FORECAST_MEASURES[\"MAPE\"](trn, prd_trn),\n",
    "            FORECAST_MEASURES[\"MAPE\"](tst, prd_tst),\n",
    "        ],\n",
    "        \"R2\": [\n",
    "            FORECAST_MEASURES[\"R2\"](trn, prd_trn),\n",
    "            FORECAST_MEASURES[\"R2\"](tst, prd_tst),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    fig, axs = subplots(1, 2, figsize=(1.5 * HEIGHT, 0.75 * HEIGHT), squeeze=True)\n",
    "    fig.suptitle(title)\n",
    "    plot_multibar_chart(\n",
    "        [\"Train\", \"Test\"],\n",
    "        ev1,\n",
    "        ax=axs[0],\n",
    "        title=\"Scale-dependent error\",\n",
    "        percentage=False,\n",
    "    )\n",
    "    plot_multibar_chart(\n",
    "        [\"Train\", \"Test\"],\n",
    "        ev2,\n",
    "        ax=axs[1],\n",
    "        title=\"Percentage error\",\n",
    "        percentage=True,\n",
    "    )\n",
    "\n",
    "    return axs\n",
    "\n",
    "params = best_params[\"params\"]\n",
    "best_length = params[0]\n",
    "\n",
    "trnX, trnY = prepare_dataset_for_lstm(train, seq_length=best_length)\n",
    "tstX, tstY = prepare_dataset_for_lstm(test, seq_length=best_length)\n",
    "prd_trn = best_model.predict(trnX).cpu().numpy().squeeze() \n",
    "prd_tst = best_model.predict(tstX).cpu().numpy().squeeze() \n",
    "\n",
    "trn_last = train[best_length:, -1]\n",
    "tst_last = test[best_length:, -1]\n",
    "\n",
    "assert len(trn_last) == len(prd_trn), \"Tamanho incompatível entre treino e previsões.\"\n",
    "assert len(tst_last) == len(prd_tst), \"Tamanho incompatível entre teste e previsões.\"\n",
    "\n",
    "plot_forecasting_eval(\n",
    "    trn_last,\n",
    "    tst_last,\n",
    "    prd_trn,\n",
    "    prd_tst,\n",
    "    title=f\"{file_tag} - LSTM (length={best_length}, hidden={params[1]}, epochs={params[2]})\",\n",
    ")\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting results obtained with the best parameterisation of LSTMs with multiple variables.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = data[[target]]\n",
    "train, test = series[:train_size], series[train_size:]\n",
    "\n",
    "pred_series = Series(prd_tst.ravel(), index=test.index[best_length:])\n",
    "\n",
    "plot_forecasting_series(\n",
    "    train[best_length:],\n",
    "    test[best_length:],\n",
    "    pred_series,\n",
    "    title=f\"{file_tag} - LSTMs\",\n",
    "    xlabel=timecol,\n",
    "    ylabel=target,\n",
    ")\n",
    "\n",
    "savefig(f\"{path_to_directory}/images/Set 1 - Forecasting plots obtained with the best parameterisation of LSTMs with multiple variables.png\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
